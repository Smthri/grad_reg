{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.models as tmodels\n",
    "from termcolor import colored\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%matplotlib inline\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "net = Net(reg_param=3.)\n",
    "\n",
    "print(net)\n",
    "\n",
    "def train(epochs):\n",
    "    min_acc = -np.inf\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    writer = SummaryWriter(comment='_cifar_lambda_3')\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.\n",
    "        val_acc = -np.inf\n",
    "        val_loss = np.inf\n",
    "        total = 0\n",
    "        pbar = tqdm(enumerate(trainloader, 0))\n",
    "        for i, data in pbar:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "            inputs.requires_grad_(requires_grad=True)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            net.optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = net.loss_fn(outputs, labels, inputs, regularize_grads=True)\n",
    "            loss.backward()\n",
    "            net.optimizer.step()\n",
    "            pred = torch.argmax(outputs, axis=1)\n",
    "            running_acc = (pred == labels).float().sum()\n",
    "            running_loss = loss.item()\n",
    "\n",
    "            epoch_acc += running_acc\n",
    "            epoch_loss += running_loss\n",
    "            \n",
    "            total += labels.size(0)\n",
    "\n",
    "            # print statistics\n",
    "            pbar.set_description(f'Epoch: {epoch}, Done {(i + 1)/len(trainloader) * 100}%, Loss: {running_loss}, Accuracy: {running_acc  / BATCH_SIZE * 100}%')\n",
    "            pbar.update(BATCH_SIZE)\n",
    "        pbar.close()\n",
    "\n",
    "        val_acc, val_loss = test(testloader)\n",
    "        \n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc /= total\n",
    "        epoch_acc *= 100\n",
    "        \n",
    "        net.scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accs.append(epoch_acc)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "        writer.add_scalar('Loss/test', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', val_acc, epoch)\n",
    "\n",
    "        #print(f\"Avg loss: {colored(str(epoch_loss), 'green')}, Avg accuracy: {colored(str(epoch_acc.item()), 'red')}, Val loss: {val_loss}, Val accuracy: {val_acc}\")\n",
    "\n",
    "        if val_acc > min_acc:\n",
    "            print(f'Improved val acc from {min_acc} to {val_acc}, saving model')\n",
    "            min_acc = val_acc\n",
    "            net.save(name=f'cifar_lambda{net.loss_fn.hp}')\n",
    "        else:\n",
    "            print(f'Val acc did not improve from {min_acc}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    writer.flush()\n",
    "    return epoch_accs, epoch_losses\n",
    "\n",
    "def test(dataloader):\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "            outputs = net(images)\n",
    "            run_loss = net.loss_fn(outputs, labels, images, regularize_grads=False).item()\n",
    "            loss += run_loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            run_acc = (predicted == labels).sum().item()\n",
    "            correct += run_acc\n",
    "\n",
    "    return correct / total * 100, loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, losses = train(150)\n",
    "acc, loss = test(testloader)\n",
    "print(f'Test acc: {acc}%, test loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save(name=f'cifar_lambda{net.loss_fn.hp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
