{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.models as tmodels\n",
    "from termcolor import colored\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from custom_transforms import QuantizeBatch\n",
    "%matplotlib inline\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5,), (.5,))\n",
    "])\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "trainset = torchvision.datasets.KMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.KMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re_param: 100.0\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
      "  (act): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Net\n",
    "lmbda = 100.\n",
    "net = Net(reg_param=lmbda, device='cuda:2')\n",
    "\n",
    "net.load(name=f'kmnist_lambda100.0')\n",
    "\n",
    "print(net)\n",
    "\n",
    "def train(epochs, defense=True):\n",
    "    min_acc = -np.inf\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    writer = SummaryWriter(comment=f'_q_kmnist_lambda_{lmbda}')\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.\n",
    "        val_acc = -np.inf\n",
    "        val_loss = np.inf\n",
    "        total = 0\n",
    "        pbar = tqdm(enumerate(trainloader, 0))\n",
    "        for i, data in pbar:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            if defense:\n",
    "                data[0] = QuantizeBatch(data[0])\n",
    "            \n",
    "            inputs, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "            inputs.requires_grad_(requires_grad=True)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            net.optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = net.loss_fn(outputs, labels, inputs, regularize_grads=True)\n",
    "            loss.backward()\n",
    "            net.optimizer.step()\n",
    "            pred = torch.argmax(outputs, axis=1)\n",
    "            running_acc = (pred == labels).float().sum()\n",
    "            running_loss = loss.item()\n",
    "\n",
    "            epoch_acc += running_acc\n",
    "            epoch_loss += running_loss\n",
    "            \n",
    "            total += labels.size(0)\n",
    "\n",
    "            # print statistics\n",
    "            pbar.set_description(f'Epoch: {epoch}, Done {(i + 1)/len(trainloader) * 100}%, Loss: {running_loss}, Accuracy: {running_acc  / BATCH_SIZE * 100}%')\n",
    "            pbar.update(BATCH_SIZE)\n",
    "        pbar.close()\n",
    "\n",
    "        val_acc, val_loss = test(testloader)\n",
    "        \n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc /= total\n",
    "        epoch_acc *= 100\n",
    "        \n",
    "        net.scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accs.append(epoch_acc)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "        writer.add_scalar('Loss/test', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', val_acc, epoch)\n",
    "\n",
    "        #print(f\"Avg loss: {colored(str(epoch_loss), 'green')}, Avg accuracy: {colored(str(epoch_acc.item()), 'red')}, Val loss: {val_loss}, Val accuracy: {val_acc}\")\n",
    "\n",
    "        if val_acc > min_acc:\n",
    "            #print(f'Improved val acc from {min_acc} to {val_acc}, saving model')\n",
    "            min_acc = val_acc\n",
    "            #net.save(name=f'kmnist_lambda{net.loss_fn.hp}')\n",
    "        else:\n",
    "            print(f'Val acc did not improve from {min_acc}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    writer.flush()\n",
    "    return epoch_accs, epoch_losses\n",
    "\n",
    "def test(dataloader):\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "            outputs = net(images)\n",
    "            run_loss = net.loss_fn(outputs, labels, images, regularize_grads=False).item()\n",
    "            loss += run_loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            run_acc = (predicted == labels).sum().item()\n",
    "            correct += run_acc\n",
    "\n",
    "    return correct / total * 100, loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Done 100.0%, Loss: 0.04418201372027397, Accuracy: 100.0%: : 1875it [06:37,  4.72it/s]               \n",
      "Epoch: 1, Done 100.0%, Loss: 0.06483405083417892, Accuracy: 100.0%: : 1875it [06:39,  4.69it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Done 100.0%, Loss: 0.14885002374649048, Accuracy: 96.875%: : 1875it [06:55,  4.51it/s]              \n",
      "Epoch: 3, Done 100.0%, Loss: 0.20340050756931305, Accuracy: 96.875%: : 1875it [06:40,  4.68it/s]              \n",
      "Epoch: 4, Done 100.0%, Loss: 0.3872072100639343, Accuracy: 93.75%: : 1875it [06:37,  4.71it/s]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Done 100.0%, Loss: 0.07207611203193665, Accuracy: 100.0%: : 1875it [07:00,  4.46it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Done 100.0%, Loss: 0.36319953203201294, Accuracy: 96.875%: : 1875it [06:34,  4.76it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Done 100.0%, Loss: 0.080357126891613, Accuracy: 100.0%: : 1875it [06:46,  4.62it/s]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Done 100.0%, Loss: 0.09410664439201355, Accuracy: 100.0%: : 1875it [07:27,  4.19it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Done 100.0%, Loss: 0.20304983854293823, Accuracy: 100.0%: : 1875it [06:53,  4.54it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc did not improve from 95.65\n",
      "Finished Training\n",
      "Test acc: 94.69999999999999%, test loss: 0.19378279700589637\n"
     ]
    }
   ],
   "source": [
    "accs, losses = train(10)\n",
    "acc, loss = test(testloader)\n",
    "print(f'Test acc: {acc}%, test loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save(name=f'q_kmnist_lambda{net.loss_fn.hp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
