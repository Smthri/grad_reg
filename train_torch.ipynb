{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.models as tmodels\n",
    "from termcolor import colored\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%matplotlib inline\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "BATCH_SIZE=32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_subset, val_subset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
      "  (act): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Net\n",
    "net = Net(BATCH_SIZE)\n",
    "\n",
    "print(net)\n",
    "\n",
    "def train(epochs):\n",
    "    min_acc = -np.inf\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.\n",
    "        val_acc = -np.inf\n",
    "        val_loss = np.inf\n",
    "        pbar = tqdm(enumerate(trainloader, 0))\n",
    "        for i, data in pbar:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            net.optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = net.loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            net.optimizer.step()\n",
    "\n",
    "            pred = torch.argmax(outputs, axis=1)\n",
    "            running_acc = (pred == labels).float().sum() / BATCH_SIZE * 100\n",
    "            running_loss = loss.item()\n",
    "\n",
    "            epoch_acc += running_acc\n",
    "            epoch_loss += running_loss\n",
    "\n",
    "            # print statistics\n",
    "            pbar.set_description(f'Epoch: {epoch}, Done {(i + 1)/len(trainloader) * 100}%, Loss: {running_loss}, Accuracy: {running_acc}%')\n",
    "            pbar.update(BATCH_SIZE)\n",
    "        pbar.close()\n",
    "\n",
    "        val_acc, val_loss = test(valloader)\n",
    "\n",
    "        net.scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc /= len(trainloader)\n",
    "        \n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accs.append(epoch_acc)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "        writer.add_scalar('Loss/test', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', val_acc, epoch)\n",
    "\n",
    "        print(f\"Avg loss: {colored(str(epoch_loss), 'green')}, Avg accuracy: {colored(str(epoch_acc.item()), 'red')}, Val loss: {val_loss}, Val accuracy: {val_acc}\")\n",
    "\n",
    "        if val_acc > min_acc:\n",
    "            print(f'Improved val acc from {min_acc} to {val_acc}, saving model')\n",
    "            min_acc = val_acc\n",
    "            net.save()\n",
    "        else:\n",
    "            print(f'Val acc did not improve from {min_acc}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    writer.flush()\n",
    "    return epoch_accs, epoch_losses\n",
    "\n",
    "def test(dataloader):\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(net.device), data[1].to(net.device)\n",
    "            outputs = net(images)\n",
    "            run_loss = net.loss_fn(outputs, labels).item()\n",
    "            loss += run_loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            run_acc = (predicted == labels).sum().item()\n",
    "            correct += run_acc\n",
    "\n",
    "    return correct / total * 100, loss / total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Done 100.0%, Loss: 1.5590554475784302, Accuracy: 46.875%: : 1250it [00:09, 129.13it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: \u001b[32m1.4953859202861786\u001b[0m, Avg accuracy: \u001b[31m46.0\u001b[0m, Val loss: 0.041197585606575014, Val accuracy: 52.910000000000004\n",
      "Improved val acc from -inf to 52.910000000000004, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Done 100.0%, Loss: 1.2841237783432007, Accuracy: 59.375%: : 1250it [00:09, 132.73it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: \u001b[32m1.2427513354301452\u001b[0m, Avg accuracy: \u001b[31m55.619998931884766\u001b[0m, Val loss: 0.03778730186223984, Val accuracy: 57.440000000000005\n",
      "Improved val acc from 52.910000000000004 to 57.440000000000005, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Done 100.0%, Loss: 0.9770117998123169, Accuracy: 68.75%: : 1250it [00:09, 132.96it/s]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: \u001b[32m1.134056944179535\u001b[0m, Avg accuracy: \u001b[31m59.71249771118164\u001b[0m, Val loss: 0.0365814757168293, Val accuracy: 58.64\n",
      "Improved val acc from 57.440000000000005 to 58.64, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Done 100.0%, Loss: 0.7804016470909119, Accuracy: 62.5%: : 1250it [00:09, 134.68it/s]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: \u001b[32m1.06313604221344\u001b[0m, Avg accuracy: \u001b[31m62.44499969482422\u001b[0m, Val loss: 0.03471260567903519, Val accuracy: 61.029999999999994\n",
      "Improved val acc from 58.64 to 61.029999999999994, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Done 100.0%, Loss: 0.8025839328765869, Accuracy: 68.75%: : 1250it [00:09, 134.74it/s]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: \u001b[32m1.0087802947998046\u001b[0m, Avg accuracy: \u001b[31m64.12999725341797\u001b[0m, Val loss: 0.03410350760221481, Val accuracy: 61.739999999999995\n",
      "Improved val acc from 61.029999999999994 to 61.739999999999995, saving model\n",
      "Finished Training\n",
      "Test acc: 62.129999999999995%, test loss: 0.03365776492357254\n"
     ]
    }
   ],
   "source": [
    "accs, losses = train(5)\n",
    "acc, loss = test(testloader)\n",
    "print(f'Test acc: {acc}%, test loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ab169629ffc21017\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ab169629ffc21017\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-da1d532d46e8ed4f\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-da1d532d46e8ed4f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 80;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=runs\n",
    "from tensorboard import notebook\n",
    "notebook.display(port=80, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 21509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
